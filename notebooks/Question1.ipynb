{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd14f5-8dbd-4551-9dc2-b9d2cf537a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "import gensim.downloader\n",
    "import os\n",
    "import wget\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee799866-2708-4acf-a083-920c0f353ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.1 Download\n",
    "\n",
    "# This downloads under the directory \"~/gensim-data\" by default\n",
    "# change GENSIM_DATA_DIR environment variable if you don't want this\n",
    "# size is about 1.6 GB\n",
    "w2v = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af645c-20b5-48fc-8e90-48fef90c71de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 million words\n",
    "len(w2v), type(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db361e-beb9-49bc-a014-da87ba7cfc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Each vector is 300 long\n",
    "print(w2v[\"compute\"][:10])\n",
    "w2v[\"compute\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18d773-b893-4127-8785-30591af1785d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Question 1.2 Download\n",
    "\n",
    "conll_raw_url = \"https://raw.githubusercontent.com/TheAnig/NER-LSTM-CNN-Pytorch/master/data/\"\n",
    "filenames = [\"eng.train\", \"eng.testa\", \"eng.testb\"] \n",
    "\n",
    "urls = {(f, f\"{conll_raw_url}/{f}\") for f in filenames}\n",
    "\n",
    "for fn, url in urls:\n",
    "    save_path = f\"data/{fn}\"\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"{fn} already exists. Skipping\")\n",
    "        continue\n",
    "    wget.download(url, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a14467-8e9f-44bb-a40b-bb99548dfb92",
   "metadata": {},
   "source": [
    "# Question 1. 1\n",
    "\n",
    "The most similar words are\n",
    "\n",
    "    (a) student:  students, 0.729\n",
    "    (b) Apple:  Apple_AAPL, 0.746\n",
    "    (c) apple:  apples, 0.720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be0f8f-b86b-4b3f-8662-53857c88d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) “student”; (b) “Apple”; (c) “apple”\n",
    "words = [\"student\", \"Apple\", \"apple\"]\n",
    "\n",
    "for w in words:\n",
    "    most_sim_w, score = w2v.most_similar(w)[0]\n",
    "    print(f\"{w}:  {most_sim_w}, {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71561fb2-9e4f-4fef-83e4-582c6b20dce6",
   "metadata": {},
   "source": [
    "# Question 1.2\n",
    "\n",
    "    (a1) training set has 14987 sentences\n",
    "    (a2) development set has 3466 sentences\n",
    "    (a3) testing set has 3684 sentences\n",
    "    (a4) train tags      : {'O', 'B-MISC', 'B-LOC', 'I-MISC', 'I-LOC', 'B-ORG', 'I-PER', 'I-ORG'}\n",
    "    (a5) development tags: {'O', 'B-MISC', 'I-MISC', 'I-LOC', 'I-PER', 'I-ORG'}\n",
    "    (a6) testing tags    : {'O', 'B-MISC', 'B-LOC', 'I-MISC', 'I-LOC', 'B-ORG', 'I-PER', 'I-ORG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b507a9a-8536-4b3d-8c76-822100bf278b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# File has one line\n",
    "\n",
    "# The tagging column that we will use\n",
    "# \n",
    "TAGGING_INDEX  = 3\n",
    "\n",
    "# Returns a 3 dim array of sentences x words x (word_value, word_category)\n",
    "def process_sets(filepath):\n",
    "    raw = open(filepath)\n",
    "    fin, curr = [], []\n",
    "    \n",
    "    for r in raw:\n",
    "        if r == \"\\n\":\n",
    "            fin.append(curr)\n",
    "            curr = []\n",
    "            continue\n",
    "            \n",
    "        r = r[:-1].split()\n",
    "\n",
    "        # Some files have these which are used to divide sentences\n",
    "        if r[0] == \"-DOCSTART-\":\n",
    "            continue\n",
    "        \n",
    "        r = [r[i] for i in (0, TAGGING_INDEX)]  # select first and last columns\n",
    "        curr.append(r)\n",
    "    \n",
    "    fin.append(curr)\n",
    "    return fin\n",
    "\n",
    "trainset = process_sets(\"data/eng.train\")\n",
    "devset = process_sets(\"data/eng.testa\")   # aka validation set\n",
    "testset = process_sets(\"data/eng.testb\")\n",
    "\n",
    "len(trainset), len(devset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c5d40-f598-4461-9ae2-5b7957f7f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = set(w[1] for s in trainset for w in s)\n",
    "dev_tags = set(w[1] for s in devset for w in s)\n",
    "test_tags = set(w[1] for s in testset for w in s)\n",
    "\n",
    "print(f\"train tags: {train_tags}\")\n",
    "print(f\"development tags: {dev_tags}\")\n",
    "print(f\"testing tags: {test_tags}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
